{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS TOPICS FACIAL GENERATION PROJECT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8lfGEvNqPeH7","colab_type":"text"},"source":["# **Neural Network Systems For Realistic Facial Generation**\n","**Carter Smith**\n","\n","**Computer Science Topics H**"]},{"cell_type":"markdown","metadata":{"id":"CZJPqMKjk1xm","colab_type":"text"},"source":["# What I Learned About Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"Z-viHhLCk8Eu","colab_type":"text"},"source":["Here is a brief summary of what I learned about neural networks while researching, as well as how I will apply this learning to my project.\n","\n","**What is a neural network & generative adversarial network?**\n","\n","A neural network is a computer system that has multiple functioning parts that communicate with each other. A GAN, or generative adversarial network, works with two parts, a generator and discriminator, that work against each other to create some sort of generated output. The simplest way to think about this is an art forger as the generator and the discriminator as the detective. The forger wants to create as realistic of a fake painting as possible to fool the detective. The detective will determine whether or not the painting is real based off of his knowledge of what real paintings look like. If he determines the painting to be fake, the forger will work differently to try to make it seem real. So the detective and forger are always in an adversarial relationship with each other.\n","![alt text](https://miro.medium.com/max/958/1*-gFsbymY9oJUQJ-A3GTfeg.png)\n","\n","**Generators**\n","\n","The process of generating an image using a GAN, or Generative Adversarial Network, begins with a random number (seed) and ends with a 1024x1024 image. The generator begins by randomly assigning color to pixels. Over time, with help from the discriminator judging its outputs, it begins to create images that are more similar to that of the dataset. As its results become more accurate, the discriminator will become more refined in its comparisons, and in return the generator will also generate more accurate images. Our goal is to use a generator structured like this one to create a realistic face image.\n","\n","![alt text](https://paper-attachments.dropbox.com/s_257816875AB071372D764C43DFB8A4901E0EBAB81800E986F1F30C17BAA9E957_1557670710523_Architecture-of-the-generator-a-and-discriminator-b-of-our-cGAN-model-The-generator.ppm.png)\n","\n","**Complete Structures**\n","\n","What makes a Generative Adversarial Network so effective is that it has 2 networks that work to refine its understanding of real data. \n","\n","The generator takes random noise and blows it up into a high quality fake image. This fake image is then compared to a real image, from the dataset, by the discriminator. The discriminator will then output a decimal that determines whether it is real or fake.\n","\n","Obviously, in early stages of training, the discriminator will easily recognize a face over randomly scrambled pixels. This is why hundreds of thousands of repetitions are needed to create a well-functioning model. Then, each iteration of the generator will make it significantly more accurate.\n","\n","![alt text](https://miro.medium.com/max/1204/0*LodTiw8Mc84eFtGF.png)\n","\n","**Latent Vectors**\n","\n","The Latent Vector is an important concept because it is at the center of the whole image generation process. The vector itself is an integer but can be turned into an image by either the generator or the discriminator. The Vector, or what is referenced in my code as an integer 'seed', represents random noise (created during the \n","expand_seed() method). It is the basis for the generator expanding it into a realistic face image. The discriminator shrinks input images into a noise vector to make a decision on its reality. \n","![alt text](https://miro.medium.com/max/1400/0*kHJ_LsPi-jz_CreZ.png)\n","\n","\n","**Datasets**\n","\n","After research, I found that the standard dataset used for facial recognition GANs is Flickr's HQ Faces Dataset found at https://github.com/NVlabs/ffhq-dataset. The set includes 70,000 PNG images of high-quality, aligned faces that are 1024x1024 pixels. This is the model that StyleGAN2 is trained on.\n","\n","Here is an example of a face that is included in the dataset:\n","\n","![alt text](https://i.ibb.co/VSty5Xb/51983.png)\n"]},{"cell_type":"markdown","metadata":{"id":"fPRTA3jjQn8Z","colab_type":"text"},"source":["# Implementing TensorFlow & Using StyleGAN2"]},{"cell_type":"code","metadata":{"id":"8wwYOemeOPbg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":145},"outputId":"4851d7cf-25af-4242-870e-7a42657ece61"},"source":["%tensorflow_version 1.x\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vvzRFjEiOYEc","colab_type":"text"},"source":["This mounts TensorFlow in Google CoLab. StyleGAN2 only supports TensorFlow 1.x.\n","\n","You will have to get a Google authorization code from [this API link](https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly). It will be formatted like '4/yAEWLEB7HRm7odqobaddR97CDnuQ50khZ_6ZcnHAJ-Vk8FCkDUHWzV4'.\n","\n","\n","This also determines where the created images will be generated in. Part of the reason I decided to use Google CoLab was because I can choose to have them generated in Google Drive.\n","\n"]},{"cell_type":"code","metadata":{"id":"5XiXdKDQP9Oj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"48d670a2-2f95-4c77-9188-2966ba349a5e"},"source":["!git clone https://github.com/NVlabs/stylegan2.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'stylegan2'...\n","remote: Enumerating objects: 93, done.\u001b[K\n","remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 93\u001b[K\n","Unpacking objects: 100% (93/93), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O6CDI7nvKUwn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"2039eab4-2257-46dd-eb43-f642a809bb10"},"source":["!ls /content/stylegan2/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dataset_tool.py  LICENSE.txt\t\t README.md\t   run_training.py\n","dnnlib\t\t metrics\t\t run_generator.py  test_nvcc.cu\n","Dockerfile\t pretrained_networks.py  run_metrics.py    training\n","docs\t\t projector.py\t\t run_projector.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DZXX_ptcPcuA","colab_type":"text"},"source":["This will add NVIDIA's 'StyleGAN2' to the local library (GAN = Generative Adversarial Network). This network, created in December 2019, represents the most recent and highest-level image-generating machine learning models. Here is a brief overview of StyleGAN2's capabilities:\n","\n","*The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. Our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality.*\n","\n","In my case, we will be utilizing the network, which has the ability to generate any object (like cars, animals, or houses) to create faces.\n","\n","StyleGAN2 is a project by NVIDIA that is trained off a dataset of tens of thousands of 1024x1024 face image files.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"un_UD3dZR0aA","colab_type":"text"},"source":["# Using StyleGAN2 by running Python Code"]},{"cell_type":"code","metadata":{"id":"7kl7spsVSOGZ","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.insert(0, \"/content/stylegan2\")\n","\n","import dnnlib"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BBmzimMPSlps","colab_type":"text"},"source":["This creates a path in Google Drive for StyleGAN2 to be installed at. It also allows for its libraries to be imported into CoLab."]},{"cell_type":"code","metadata":{"id":"C_x5n4echFOG","colab_type":"code","colab":{}},"source":["import argparse\n","import numpy as np\n","import pickle\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import re\n","import sys\n","import pretrained_networks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vD4waMBGhL6Y","colab_type":"text"},"source":["This imports all the required libraries for StyleGAN2 to operate. Many of them are unique to Python (including NumPy / PIL.image), TensorFlow (tflib), or StyleGAN itself (dnnlib)"]},{"cell_type":"code","metadata":{"id":"febKtws-hOU4","colab_type":"code","colab":{}},"source":["##This method takes a random integer seed (i.e. 7000) and expands it into an array of random numbers of noise.\n","##According to the way StyleGAN2 works, vector_size is 512x512. So each seed will be expanded into an array of 512 random numbers.\n","##This method will fill each array, using NumPy's RandomState(), with random numbers. The generator will later turn these values into noise.\n","def expand_seed(seeds, vector_size):\n","    result = []\n","\n","    for seed in seeds:\n","      rnd = np.random.RandomState(seed)\n","      result.append( rnd.randn(1, vector_size) ) \n","\n","    return result\n","\n","##This method generates the actual face images using the FFHQ trained StyleGAN network.\n","##It takes in 'Gs', or the neural network .pkl file itself, a seed that will be generated, and \n","##truncation_psi, a variable created by StyleGAN2, that is supposed to make the image clearer. (It is defined in the network, I only included it because it was recommended)\n","##This is done by referencing the specific methods & variables of the network using 'kwargs' and with a lot of for each loops\n","def generate_images(Gs, seeds, truncation_psi):\n","    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n","    \n","    Gs_kwargs = dnnlib.EasyDict()\n","    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    Gs_kwargs.randomize_noise = False\n","\n","    if truncation_psi is not None:\n","        Gs_kwargs.truncation_psi = truncation_psi\n","\n","##This loop specifically takes the seed, enumerates it (assigns pixel #s to noise variables), and gives it to the network to process in Gs.run()\n","##It also does the actual image conversion by taking the converted array of pixels defined in images[] and saving it as an RGB image using PIL.image.fromarray().save()\n","    for seed_idx, seed in enumerate(seeds):\n","        print('%d/%d' % (seed_idx, len(seeds)))\n","        rnd = np.random.RandomState()\n","        tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars})\n","        images = Gs.run(seed, None, **Gs_kwargs)\n","        path = f\"/content/drive/My Drive/machinelearning/image{seed_idx}.png\"\n","        PIL.Image.fromarray(images[0], 'RGB').save(path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pXNNuBA-hXDe","colab_type":"text"},"source":["Defining methods that, using random latent image 'seeds,' create random faces based off of StyleGAN2's model.\n","\n"]},{"cell_type":"code","metadata":{"id":"e88jjhmIlaaa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"f08fca74-8581-4aa6-a93f-5784886eb5b4"},"source":["##This main method accesses StyleGan's 'dnnlib' to run it (by assigning it a path in Google Drive & the 'generate-images' variable), \n","##as well as directs the network (in the Python serialized form of .pkl) to run on the dedicated CoLab GPU \n","def main():\n","    sc = dnnlib.SubmitConfig()\n","    sc.num_gpus = 1\n","    sc.submit_target = dnnlib.SubmitTarget.LOCAL\n","    sc.local.do_not_copy_source_files = True\n","    sc.run_dir_root = \"/content/drive/My Drive/machinelearning\"\n","    sc.run_desc = 'generate-images'\n","    network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'\n","\n","##This loads the network by assigning it to the Gs variable and defines the seeds to expand and generate\n","##It does this by calling the expand_seed() and generate_images() methods\n","    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n","    vector_size = Gs.input_shape[1:][0]\n","    seeds = expand_seed( range(7992,7995), vector_size)\n","    generate_images(Gs, seeds,truncation_psi=0.5)\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n","##IF I HAD MORE TIME, I WOULD HAVE MESSED AROUND WITH THE LATENT VECTOR TO CHANGE THE IMAGES, ENCODED MYSELF, ETC"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl ... done\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n","0/3\n","1/3\n","2/3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I8tQXRrwlh1x","colab_type":"text"},"source":["Defining a main method that will actually generate random images based off of a # seed input.\n","\n","**MAKE SURE GPU ACCELERATION IS ENABLED FOR THE NOTEBOOK** "]}]}